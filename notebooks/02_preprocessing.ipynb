{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e972bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([0, 1, 2, 3, 4, 5], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_csv = r\"C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\7rada\\Catalog_products_patchi.xlsx\"\n",
    "pat =r\"C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\cleaned_sheets\\NO ADDED SUGAR_cleaned.xlsx\"\n",
    "# Lire toutes les feuilles\n",
    "df = pd.read_excel(pat) \n",
    "df = df.dropna(axis=1, how='all')  # drop columns where all values are NaN\n",
    "print(df.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7c014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['codes ', 'Name ', 'new  Photo ', 'filling', 'Weight ', 'Price'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_csv = r\"C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\7rada\\feuilles_extraites\\NO ADDED SUGAR.xlsx\"\n",
    "df = pd.read_excel(output_csv) \n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2f7f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Catalog Columns ===\n",
      "['ordering_index', 'id', 'title', 'price', 'description', 'availability', 'condition', 'link', 'image_link', 'additional_image_link', 'brand', 'google_product_category', 'fb_product_category', 'quantity_to_sell_on_facebook', 'sale_price', 'sale_price_effective_date', 'item_group_id', 'gender', 'color', 'size', 'age_group', 'material', 'pattern', 'shipping', 'shipping_weight', 'gtin', 'video[0].url', 'video[0].tag[0]', 'product_tags[0]', 'product_tags[1]', 'style[0]', 'retailer_id']\n",
      "Current products in catalog: 471\n",
      "\n",
      "=== Processing:  MY Treats.xlsx ===\n",
      "Sheet columns: ['codes', 'name', 'New Photo', \"What's Inside Photo\", 'filling', 'Final Weight', 'Price', 'Unnamed: 7', 'Unnamed: 8']\n",
      "Products found: 22\n",
      "‚úì Added 22 products from  MY Treats\n",
      "\n",
      "‚äó Skipping main catalog file: Catalog_products_patchi.xlsx\n",
      "\n",
      "=== Processing: CHOCOLATE BARS.xlsx ===\n",
      "Sheet columns: ['Code', 'Name', 'Photo', \"What's Inside Photo\", 'weight', 'ORDER']\n",
      "Products found: 15\n",
      "‚ö† Missing 'price' column (tried: price, Price, prix, Prix)\n",
      "Skipping this sheet...\n",
      "\n",
      "=== Processing: GIFT BOXES.xlsx ===\n",
      "Sheet columns: ['Codes', 'Name', 'New Photo', \"What's Inside Photo\", 'Final fillin', 'Final weiht', 'nb of pcs', 'Prix']\n",
      "Products found: 13\n",
      "‚úì Added 13 products from GIFT BOXES\n",
      "\n",
      "=== Processing: HOME SPECIAL.xlsx ===\n",
      "Sheet columns: ['Codes', 'Name', 'Old Photo', 'New Photo', \"What's Inside Photo\", 'Final filling', 'weight', 'nb of pcs', 'shelf life', 'Price $', 'Price']\n",
      "Products found: 4\n",
      "‚úì Added 4 products from HOME SPECIAL\n",
      "\n",
      "=== Processing: MINIS .xlsx ===\n",
      "Sheet columns: ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6']\n",
      "Products found: 5\n",
      "‚ö† Missing 'codes' column (tried: codes, code, Code, Codes)\n",
      "Skipping this sheet...\n",
      "\n",
      "=== Processing: NO ADDED SUGAR.xlsx ===\n",
      "Sheet columns: ['codes', 'Name', 'new  Photo', 'filling', 'Weight', 'Price']\n",
      "Products found: 25\n",
      "‚úì Added 25 products from NO ADDED SUGAR\n",
      "\n",
      "=== Processing: SMALL BOXES.xlsx ===\n",
      "Sheet columns: ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6']\n",
      "Products found: 26\n",
      "‚ö† Missing 'codes' column (tried: codes, code, Code, Codes)\n",
      "Skipping this sheet...\n",
      "\n",
      "==================================================\n",
      "‚úì COMPLETED!\n",
      "Total products added: 64\n",
      "Final catalog now has: 535 products\n",
      "Saved to: C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\7rada\\Catalog_products_patchi.xlsx\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to final merged catalog\n",
    "final_path = r\"C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\7rada\\Catalog_products_patchi.xlsx\"\n",
    "\n",
    "# Load the final catalog (must exist)\n",
    "final_df = pd.read_excel(final_path)\n",
    "\n",
    "print(\"=== Final Catalog Columns ===\")\n",
    "print(final_df.columns.tolist())\n",
    "print(f\"Current products in catalog: {len(final_df)}\")\n",
    "\n",
    "# Directory containing extracted sheets\n",
    "sheets_dir = Path(r\"C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\7rada\\feuilles_extraites\")\n",
    "\n",
    "# Counter for total products added\n",
    "total_added = 0\n",
    "\n",
    "# Helper function to find column by possible names (case-insensitive)\n",
    "def find_column(df, possible_names):\n",
    "    \"\"\"Find a column in dataframe by checking multiple possible names (case-insensitive)\"\"\"\n",
    "    df_cols_lower = {col.lower(): col for col in df.columns}\n",
    "    \n",
    "    for name in possible_names:\n",
    "        if name.lower() in df_cols_lower:\n",
    "            return df_cols_lower[name.lower()]\n",
    "    return None\n",
    "\n",
    "# Process each Excel file in the directory\n",
    "for sheet_file in sheets_dir.glob(\"*.xlsx\"):\n",
    "    # Skip the main catalog file itself\n",
    "    if sheet_file.name == \"Catalog_products_patchi.xlsx\":\n",
    "        print(f\"\\n‚äó Skipping main catalog file: {sheet_file.name}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n=== Processing: {sheet_file.name} ===\")\n",
    "    \n",
    "    try:\n",
    "        # Load the extracted product sheet\n",
    "        df = pd.read_excel(sheet_file)\n",
    "        \n",
    "        # Clean column names (remove trailing/leading spaces)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        print(f\"Sheet columns: {df.columns.tolist()}\")\n",
    "        print(f\"Products found: {len(df)}\")\n",
    "        \n",
    "        # Find columns with flexible matching\n",
    "        col_code = find_column(df, [\"codes\", \"code\", \"codes \", \"Code\", \"Codes\"])\n",
    "        col_name = find_column(df, [\"name\", \"Name\", \"name \", \"Name \"])\n",
    "        col_price = find_column(df, [\"price\", \"Price\", \"prix\", \"Prix\", \"price \", \"Price \"])\n",
    "        col_photo = find_column(df, [\"new photo\", \"new  photo\", \"photo\", \"Photo\", \"New Photo\"])\n",
    "        col_filling = find_column(df, [\"filling\", \"Filling\", \"Final fillin\"])\n",
    "        col_weight = find_column(df, [\"weight\", \"Weight\", \"weight \", \"Weight \", \"Final Weight\", \"Final weiht\"])\n",
    "        \n",
    "        # Check if essential columns exist\n",
    "        if not col_code:\n",
    "            print(f\"‚ö† Missing 'codes' column (tried: codes, code, Code, Codes)\")\n",
    "            print(\"Skipping this sheet...\")\n",
    "            continue\n",
    "        \n",
    "        if not col_name:\n",
    "            print(f\"‚ö† Missing 'name' column (tried: name, Name)\")\n",
    "            print(\"Skipping this sheet...\")\n",
    "            continue\n",
    "        \n",
    "        if not col_price:\n",
    "            print(f\"‚ö† Missing 'price' column (tried: price, Price, prix, Prix)\")\n",
    "            print(\"Skipping this sheet...\")\n",
    "            continue\n",
    "        \n",
    "        # Check for empty IDs\n",
    "        empty_ids = df[col_code].isna().sum()\n",
    "        if empty_ids > 0:\n",
    "            print(f\"‚ö† Found {empty_ids} products with missing IDs - removing them\")\n",
    "            df = df[df[col_code].notna()]\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            print(\"‚ö† No valid products left after filtering\")\n",
    "            continue\n",
    "        \n",
    "        # Use filename as brand name (without extension)\n",
    "        brand_name = sheet_file.stem\n",
    "        \n",
    "        # Build the dataframe with ALL required columns\n",
    "        mapped_df = pd.DataFrame({\n",
    "            \"ordering_index\": range(len(final_df), len(final_df) + len(df)),\n",
    "            \"id\": df[col_code],\n",
    "            \"title\": df[col_name],\n",
    "            \"price\": df[col_price],\n",
    "            \"description\": df[col_filling] if col_filling else \"\",\n",
    "            \"availability\": \"in stock\",\n",
    "            \"condition\": \"new\",\n",
    "            \"link\": \"\",\n",
    "            \"image_link\": df[col_photo] if col_photo else \"\",\n",
    "            \"additional_image_link\": \"\",\n",
    "            \"brand\": brand_name,\n",
    "            \"google_product_category\": \"\",\n",
    "            \"fb_product_category\": \"\",\n",
    "            \"quantity_to_sell_on_facebook\": \"\",\n",
    "            \"sale_price\": \"\",\n",
    "            \"sale_price_effective_date\": \"\",\n",
    "            \"item_group_id\": \"\",\n",
    "            \"gender\": \"\",\n",
    "            \"color\": \"\",\n",
    "            \"size\": \"\",\n",
    "            \"age_group\": \"\",\n",
    "            \"material\": \"\",\n",
    "            \"pattern\": \"\",\n",
    "            \"shipping\": \"\",\n",
    "            \"shipping_weight\": df[col_weight] if col_weight else \"\",\n",
    "            \"gtin\": \"\",\n",
    "            \"video[0].url\": \"\",\n",
    "            \"video[0].tag[0]\": \"\",\n",
    "            \"product_tags[0]\": \"\",\n",
    "            \"product_tags[1]\": \"\",\n",
    "            \"style[0]\": \"\",\n",
    "            \"retailer_id\": \"\"\n",
    "        })\n",
    "        \n",
    "        # Append to final catalog\n",
    "        final_df = pd.concat([final_df, mapped_df], ignore_index=True)\n",
    "        \n",
    "        total_added += len(mapped_df)\n",
    "        print(f\"‚úì Added {len(mapped_df)} products from {brand_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {sheet_file.name}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "# Save updated catalog\n",
    "final_df.to_excel(final_path, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"‚úì COMPLETED!\")\n",
    "print(f\"Total products added: {total_added}\")\n",
    "print(f\"Final catalog now has: {len(final_df)} products\")\n",
    "print(f\"Saved to: {final_path}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74c50457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture du fichier: C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\7rada\\Dashysk.xlsx\n",
      "Nombre de feuilles trouv√©es: 7\n",
      "Noms des feuilles: ['HOME SPECIAL', 'SMALL BOXES', 'MINIS ', ' MY Treats', 'NO ADDED SUGAR', 'CHOCOLATE BARS', 'GIFT BOXES']\n",
      "\n",
      "Traitement de la feuille: 'HOME SPECIAL'\n",
      "  - Dimensions originales: (5, 11)\n",
      "  - Dimensions apr√®s nettoyage: (5, 11)\n",
      "  ‚úì Sauvegard√© dans: cleaned_sheets\\HOME SPECIAL_cleaned.xlsx\n",
      "\n",
      "Traitement de la feuille: 'SMALL BOXES'\n",
      "  - Dimensions originales: (27, 7)\n",
      "  - Dimensions apr√®s nettoyage: (24, 5)\n",
      "  ‚úì Sauvegard√© dans: cleaned_sheets\\SMALL BOXES_cleaned.xlsx\n",
      "\n",
      "Traitement de la feuille: 'MINIS '\n",
      "  - Dimensions originales: (6, 7)\n",
      "  - Dimensions apr√®s nettoyage: (3, 5)\n",
      "  ‚úì Sauvegard√© dans: cleaned_sheets\\MINIS _cleaned.xlsx\n",
      "\n",
      "Traitement de la feuille: ' MY Treats'\n",
      "  - Dimensions originales: (23, 9)\n",
      "  - Dimensions apr√®s nettoyage: (23, 8)\n",
      "  ‚úì Sauvegard√© dans: cleaned_sheets\\ MY Treats_cleaned.xlsx\n",
      "\n",
      "Traitement de la feuille: 'NO ADDED SUGAR'\n",
      "  - Dimensions originales: (26, 6)\n",
      "  - Dimensions apr√®s nettoyage: (26, 6)\n",
      "  ‚úì Sauvegard√© dans: cleaned_sheets\\NO ADDED SUGAR_cleaned.xlsx\n",
      "\n",
      "Traitement de la feuille: 'CHOCOLATE BARS'\n",
      "  - Dimensions originales: (16, 6)\n",
      "  - Dimensions apr√®s nettoyage: (16, 6)\n",
      "  ‚úì Sauvegard√© dans: cleaned_sheets\\CHOCOLATE BARS_cleaned.xlsx\n",
      "\n",
      "Traitement de la feuille: 'GIFT BOXES'\n",
      "  - Dimensions originales: (14, 8)\n",
      "  - Dimensions apr√®s nettoyage: (14, 8)\n",
      "  ‚úì Sauvegard√© dans: cleaned_sheets\\GIFT BOXES_cleaned.xlsx\n",
      "\n",
      "Traitement termin√©! 7 fichiers cr√©√©s dans 'cleaned_sheets/'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "from pathlib import Path\n",
    "\n",
    "def find_header_row(df):\n",
    "    \"\"\"\n",
    "    D√©tecte la premi√®re ligne non vide qui semble √™tre un en-t√™te.\n",
    "    Retourne l'index de la ligne d'en-t√™te.\n",
    "    \"\"\"\n",
    "    for idx, row in df.iterrows():\n",
    "        # Compte le nombre de valeurs non-nulles dans la ligne\n",
    "        non_null_count = row.notna().sum()\n",
    "        \n",
    "        # Si au moins 50% des colonnes ont des valeurs, c'est probablement l'en-t√™te\n",
    "        if non_null_count >= len(row) * 0.5:\n",
    "            return idx\n",
    "    \n",
    "    return 0  # Par d√©faut, premi√®re ligne\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    \"\"\"\n",
    "    Nettoie le DataFrame en:\n",
    "    - D√©tectant l'en-t√™te r√©el\n",
    "    - Supprimant les lignes vides\n",
    "    - Supprimant les colonnes enti√®rement vides\n",
    "    - R√©initialisant l'index\n",
    "    \"\"\"\n",
    "    # Trouve la ligne d'en-t√™te\n",
    "    header_idx = find_header_row(df)\n",
    "    \n",
    "    # Si l'en-t√™te n'est pas √† la premi√®re ligne, r√©organise le DataFrame\n",
    "    if header_idx > 0:\n",
    "        # Utilise la ligne trouv√©e comme en-t√™tes\n",
    "        new_headers = df.iloc[header_idx].fillna('Unnamed')\n",
    "        df = df.iloc[header_idx + 1:].copy()\n",
    "        df.columns = new_headers\n",
    "    \n",
    "    # Supprime les lignes enti√®rement vides\n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    # Supprime les colonnes enti√®rement vides\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    # R√©initialise l'index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Nettoie les noms de colonnes (supprime espaces superflus)\n",
    "    df.columns = df.columns.str.strip() if df.columns.dtype == 'object' else df.columns\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_excel_file(input_file, output_dir='cleaned_sheets'):\n",
    "    \"\"\"\n",
    "    Traite un fichier Excel avec plusieurs feuilles:\n",
    "    - Lit toutes les feuilles\n",
    "    - Nettoie chaque feuille\n",
    "    - Sauvegarde chaque feuille dans un fichier Excel s√©par√©\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Chemin vers le fichier Excel d'entr√©e\n",
    "        output_dir (str): Dossier de sortie pour les fichiers nettoy√©s\n",
    "    \"\"\"\n",
    "    # Cr√©e le dossier de sortie s'il n'existe pas\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"Lecture du fichier: {input_file}\")\n",
    "    \n",
    "    # Lit toutes les feuilles du fichier Excel\n",
    "    excel_file = pd.ExcelFile(input_file)\n",
    "    sheet_names = excel_file.sheet_names\n",
    "    \n",
    "    print(f\"Nombre de feuilles trouv√©es: {len(sheet_names)}\")\n",
    "    print(f\"Noms des feuilles: {sheet_names}\\n\")\n",
    "    \n",
    "    # Traite chaque feuille\n",
    "    for sheet_name in sheet_names:\n",
    "        print(f\"Traitement de la feuille: '{sheet_name}'\")\n",
    "        \n",
    "        # Lit la feuille sans en-t√™te pr√©d√©fini\n",
    "        df = pd.read_excel(input_file, sheet_name=sheet_name, header=None)\n",
    "        \n",
    "        print(f\"  - Dimensions originales: {df.shape}\")\n",
    "        \n",
    "        # Nettoie le DataFrame\n",
    "        df_cleaned = clean_dataframe(df)\n",
    "        \n",
    "        print(f\"  - Dimensions apr√®s nettoyage: {df_cleaned.shape}\")\n",
    "        \n",
    "        # Cr√©e un nom de fichier s√©curis√©\n",
    "        safe_sheet_name = \"\".join(c if c.isalnum() or c in (' ', '_', '-') else '_' \n",
    "                                   for c in sheet_name)\n",
    "        output_file = output_path / f\"{safe_sheet_name}_cleaned.xlsx\"\n",
    "        \n",
    "        # Sauvegarde dans un nouveau fichier Excel\n",
    "        df_cleaned.to_excel(output_file, index=False, engine='openpyxl')\n",
    "        \n",
    "        print(f\"  ‚úì Sauvegard√© dans: {output_file}\\n\")\n",
    "    \n",
    "    print(f\"Traitement termin√©! {len(sheet_names)} fichiers cr√©√©s dans '{output_dir}/'\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # Remplace par le chemin de ton fichier Excel\n",
    "    input_excel = r\"C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\7rada\\Dashysk.xlsx\"\n",
    "    \n",
    "    # Lance le traitement\n",
    "    process_excel_file(input_excel, output_dir='cleaned_sheets')\n",
    "    \n",
    "    # Si tu veux traiter un fichier sp√©cifique\n",
    "    # process_excel_file(\"mon_fichier.xlsx\", output_dir=\"resultats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c49cf495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fixed header for  MY Treats_cleaned.xlsx\n",
      "File:  MY Treats_cleaned.xlsx\n",
      "Columns: ['id', 'title', 'New Photo ', \"What's Inside Photo \", 'description', 'Final Weight ', 'price', 'Unnamed: 7']\n",
      "----------------------------------------\n",
      "‚úÖ Fixed header for CHOCOLATE BARS_cleaned.xlsx\n",
      "File: CHOCOLATE BARS_cleaned.xlsx\n",
      "Columns: ['id', 'title', 'Photo', 'description', 'weight', 'price']\n",
      "----------------------------------------\n",
      "‚úÖ Fixed header for GIFT BOXES_cleaned.xlsx\n",
      "File: GIFT BOXES_cleaned.xlsx\n",
      "Columns: ['id', 'title', 'New Photo', \"What's Inside Photo \", 'description', 'Final weiht ', 'nb of pcs', 'price']\n",
      "----------------------------------------\n",
      "‚úÖ Fixed header for HOME SPECIAL_cleaned.xlsx\n",
      "File: HOME SPECIAL_cleaned.xlsx\n",
      "Columns: ['id', 'title', 'Old Photo', 'New Photo', \"What's Inside Photo \", 'description', 'weight ', 'nb of pcs', 'shelf life', 'Price $', 'price']\n",
      "----------------------------------------\n",
      "‚úÖ Header already correct for MINIS _cleaned.xlsx\n",
      "File: MINIS _cleaned.xlsx\n",
      "Columns: ['id', 'title', 'description', 'Final Weight', 'price']\n",
      "----------------------------------------\n",
      "‚úÖ Fixed header for NO ADDED SUGAR_cleaned.xlsx\n",
      "File: NO ADDED SUGAR_cleaned.xlsx\n",
      "Columns: ['id', 'title', 'new  Photo ', 'description', 'Weight ', 'price']\n",
      "----------------------------------------\n",
      "‚úÖ Header already correct for SMALL BOXES_cleaned.xlsx\n",
      "File: SMALL BOXES_cleaned.xlsx\n",
      "Columns: ['id', 'title', 'description', 'final weight', 'price']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = r\"C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\cleaned_sheets\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".xlsx\") or filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Lire le fichier\n",
    "        if filename.endswith(\".xlsx\"):\n",
    "            df = pd.read_excel(file_path, header=None)  # lire sans header pour v√©rifier\n",
    "        else:\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "        \n",
    "        # V√©rifier si les colonnes sont des nombres (0,1,2‚Ä¶)\n",
    "        if all(isinstance(col, int) for col in df.iloc[0]):\n",
    "            # Si oui, prendre la vraie ligne d'en-t√™te (ligne 2)\n",
    "            if filename.endswith(\".xlsx\"):\n",
    "                df = pd.read_excel(file_path, header=1)\n",
    "            else:\n",
    "                df = pd.read_csv(file_path, header=1)\n",
    "            print(f\"‚úÖ Fixed header for {filename}\")\n",
    "        else:\n",
    "            # Sinon, garder les colonnes existantes\n",
    "            df.columns = df.iloc[0]  # mettre la premi√®re ligne comme nom de colonnes\n",
    "            df = df[1:]  # supprimer cette ligne de donn√©es\n",
    "            print(f\"‚úÖ Header already correct for {filename}\")\n",
    "        \n",
    "        # Afficher les colonnes\n",
    "        print(f\"File: {filename}\")\n",
    "        print(\"Columns:\", df.columns.tolist())\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df3e301b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ordering_index', 'id', 'title', 'price', 'description', 'availability',\n",
      "       'condition', 'link', 'image_link', 'additional_image_link', 'brand',\n",
      "       'google_product_category', 'fb_product_category',\n",
      "       'quantity_to_sell_on_facebook', 'sale_price',\n",
      "       'sale_price_effective_date', 'item_group_id', 'gender', 'color', 'size',\n",
      "       'age_group', 'material', 'pattern', 'shipping', 'shipping_weight',\n",
      "       'gtin', 'video[0].url', 'video[0].tag[0]', 'product_tags[0]',\n",
      "       'product_tags[1]', 'style[0]', 'retailer_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Path to the new Excel file\n",
    "new_file = r\"C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\Catalog_products_columns_only.xlsx\"\n",
    "\n",
    "# Lire le fichier original pour r√©cup√©rer les colonnes\n",
    "df = pd.read_excel(new_file)\n",
    "\n",
    "\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24f115bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Lecture des fichiers depuis: C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\cleaned_sheets\n",
      "\n",
      "üìÑ Traitement de:  MY Treats_cleaned.xlsx\n",
      "   ‚úì 22 produits ajout√©s\n",
      "   Colonnes trouv√©es: ['id', 'title', 'new photo', \"what's inside photo\", 'description', 'final weight', 'price', 'unnamed: 7']\n",
      "\n",
      "üìÑ Traitement de: CHOCOLATE BARS_cleaned.xlsx\n",
      "   ‚úì 15 produits ajout√©s\n",
      "   Colonnes trouv√©es: ['id', 'title', 'photo', 'description', 'weight', 'price']\n",
      "\n",
      "üìÑ Traitement de: GIFT BOXES_cleaned.xlsx\n",
      "   ‚úì 13 produits ajout√©s\n",
      "   Colonnes trouv√©es: ['id', 'title', 'new photo', \"what's inside photo\", 'description', 'final weiht', 'nb of pcs', 'price']\n",
      "\n",
      "üìÑ Traitement de: HOME SPECIAL_cleaned.xlsx\n",
      "   ‚úì 4 produits ajout√©s\n",
      "   Colonnes trouv√©es: ['id', 'title', 'old photo', 'new photo', \"what's inside photo\", 'description', 'weight', 'nb of pcs', 'shelf life', 'price $', 'price']\n",
      "\n",
      "üìÑ Traitement de: MINIS _cleaned.xlsx\n",
      "   ‚úì 3 produits ajout√©s\n",
      "   Colonnes trouv√©es: ['id', 'title', 'description', 'final weight', 'price']\n",
      "\n",
      "üìÑ Traitement de: NO ADDED SUGAR_cleaned.xlsx\n",
      "   ‚úì 25 produits ajout√©s\n",
      "   Colonnes trouv√©es: ['id', 'title', 'new  photo', 'description', 'weight', 'price']\n",
      "\n",
      "üìÑ Traitement de: SMALL BOXES_cleaned.xlsx\n",
      "   ‚úì 24 produits ajout√©s\n",
      "   Colonnes trouv√©es: ['id', 'title', 'description', 'final weight', 'price']\n",
      "\n",
      "üîó Fusion de 7 fichiers...\n",
      "üíæ Sauvegarde dans: C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\Catalog_products_columns_only.xlsx\n",
      "\n",
      "============================================================\n",
      "‚úÖ FUSION TERMIN√âE!\n",
      "============================================================\n",
      "üìä Fichiers trait√©s: 7\n",
      "‚ö†Ô∏è  Fichiers ignor√©s: 0\n",
      "üõçÔ∏è  Total produits: 106\n",
      "üìÅ Fichier cr√©√©: C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\Catalog_products_columns_only.xlsx\n",
      "============================================================\n",
      "\n",
      "üìà R√©partition par marque:\n",
      "brand\n",
      "NO ADDED SUGAR    25\n",
      "SMALL BOXES       24\n",
      " MY Treats        22\n",
      "CHOCOLATE BARS    15\n",
      "GIFT BOXES        13\n",
      "HOME SPECIAL       4\n",
      "MINIS              3\n",
      "\n",
      "üëÄ Aper√ßu des 5 premi√®res lignes:\n",
      "   ordering_index       id          title  price  \\\n",
      "0               0  GTR0005   les Nougats     190   \n",
      "1               1  GTR0007   Croq'Amandes    240   \n",
      "2               2  GTR0008    Croq'Peanut    280   \n",
      "3               3  GTR0009    Croq'Sesame    280   \n",
      "4               4  GTR0010   Croq'Rochers    280   \n",
      "\n",
      "                                         description availability condition  \\\n",
      "0                          nougat new packaging PET      in stock       new   \n",
      "1   Caramelized almonds \\ndipped in milk  chocolate      in stock       new   \n",
      "2  Peanut croquant coated with \\nmilk chocolate d...     in stock       new   \n",
      "3  Sesame croquant coated with\\n milk chocolate a...     in stock       new   \n",
      "4                       unwrapped Rocher Chocolates      in stock       new   \n",
      "\n",
      "  link image_link additional_image_link  ... pattern shipping shipping_weight  \\\n",
      "0                                        ...                                    \n",
      "1                                        ...                                    \n",
      "2                                        ...                                    \n",
      "3                                        ...                                    \n",
      "4                                        ...                                    \n",
      "\n",
      "  gtin video[0].url video[0].tag[0] product_tags[0] product_tags[1] style[0]  \\\n",
      "0                                                                              \n",
      "1                                                                              \n",
      "2                                                                              \n",
      "3                                                                              \n",
      "4                                                                              \n",
      "\n",
      "  retailer_id  \n",
      "0              \n",
      "1              \n",
      "2              \n",
      "3              \n",
      "4              \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def merge_product_catalogs(folder_path, output_file):\n",
    "    \"\"\"\n",
    "    Fusionne plusieurs fichiers Excel/CSV en un seul catalogue produits\n",
    "    avec des colonnes standardis√©es.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Chemin du dossier contenant les fichiers\n",
    "        output_file (str): Chemin du fichier de sortie\n",
    "    \"\"\"\n",
    "    \n",
    "    # Colonnes finales standardis√©es\n",
    "    final_columns = [\n",
    "        'ordering_index', 'id', 'title', 'price', 'description', 'availability', \n",
    "        'condition', 'link', 'image_link', 'additional_image_link', 'brand',\n",
    "        'google_product_category', 'fb_product_category',\n",
    "        'quantity_to_sell_on_facebook', 'sale_price',\n",
    "        'sale_price_effective_date', 'item_group_id', 'gender', 'color', 'size',\n",
    "        'age_group', 'material', 'pattern', 'shipping', 'shipping_weight',\n",
    "        'gtin', 'video[0].url', 'video[0].tag[0]', 'product_tags[0]',\n",
    "        'product_tags[1]', 'style[0]', 'retailer_id'\n",
    "    ]\n",
    "    \n",
    "    # Liste pour stocker tous les DataFrames\n",
    "    all_dataframes = []\n",
    "    \n",
    "    # Compteurs\n",
    "    files_processed = 0\n",
    "    files_skipped = 0\n",
    "    total_products = 0\n",
    "    \n",
    "    print(f\"üìÇ Lecture des fichiers depuis: {folder_path}\\n\")\n",
    "    \n",
    "    # Parcourir tous les fichiers du dossier\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if not (filename.endswith('.xlsx') or filename.endswith('.csv')):\n",
    "            continue\n",
    "        \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        try:\n",
    "            # Lire le fichier\n",
    "            print(f\"üìÑ Traitement de: {filename}\")\n",
    "            \n",
    "            if filename.endswith('.xlsx'):\n",
    "                # Essayer d'abord sans header sp√©cifique\n",
    "                df = pd.read_excel(file_path)\n",
    "                \n",
    "                # Si la premi√®re ligne semble √™tre un header num√©rique, skip\n",
    "                if df.columns[0] == 0 or str(df.columns[0]).isdigit():\n",
    "                    df = pd.read_excel(file_path, header=1)\n",
    "            else:\n",
    "                df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Nettoyer les noms de colonnes\n",
    "            df.columns = df.columns.str.strip().str.lower()\n",
    "            \n",
    "            # V√©rifier les colonnes essentielles\n",
    "            required_cols = ['id', 'title', 'description', 'price']\n",
    "            missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "            \n",
    "            if len(missing_cols) >= 3:  # Si plus de 3 colonnes manquent\n",
    "                print(f\"   ‚ö†Ô∏è  Ignor√© - colonnes manquantes: {missing_cols}\\n\")\n",
    "                files_skipped += 1\n",
    "                continue\n",
    "            \n",
    "            # Extraire le nom de marque depuis le nom du fichier\n",
    "            brand_name = filename.replace('_cleaned.xlsx', '').replace('.xlsx', '').replace('_cleaned', '')\n",
    "            \n",
    "            # Cr√©er le DataFrame mapp√© avec les colonnes standardis√©es\n",
    "            mapped_data = {\n",
    "                'id': df.get('id', ''),\n",
    "                'title': df.get('title', df.get('product_name', df.get('name', ''))),\n",
    "                'price': df.get('price', df.get('prix', '')),\n",
    "                'description': df.get('description', df.get('desc', '')),\n",
    "                'availability': 'in stock',\n",
    "                'condition': 'new',\n",
    "                'link': df.get('link', df.get('url', '')),\n",
    "                'image_link': df.get('image_link', df.get('image', '')),\n",
    "                'additional_image_link': df.get('additional_image_link', ''),\n",
    "                'brand': brand_name,\n",
    "                'google_product_category': df.get('google_product_category', ''),\n",
    "                'fb_product_category': df.get('fb_product_category', ''),\n",
    "                'quantity_to_sell_on_facebook': df.get('quantity_to_sell_on_facebook', ''),\n",
    "                'sale_price': df.get('sale_price', ''),\n",
    "                'sale_price_effective_date': df.get('sale_price_effective_date', ''),\n",
    "                'item_group_id': df.get('item_group_id', ''),\n",
    "                'gender': df.get('gender', ''),\n",
    "                'color': df.get('color', df.get('couleur', '')),\n",
    "                'size': df.get('size', df.get('taille', '')),\n",
    "                'age_group': df.get('age_group', ''),\n",
    "                'material': df.get('material', df.get('matiere', '')),\n",
    "                'pattern': df.get('pattern', ''),\n",
    "                'shipping': df.get('shipping', ''),\n",
    "                'shipping_weight': df.get('shipping_weight', ''),\n",
    "                'gtin': df.get('gtin', ''),\n",
    "                'video[0].url': df.get('video[0].url', ''),\n",
    "                'video[0].tag[0]': df.get('video[0].tag[0]', ''),\n",
    "                'product_tags[0]': df.get('product_tags[0]', ''),\n",
    "                'product_tags[1]': df.get('product_tags[1]', ''),\n",
    "                'style[0]': df.get('style[0]', ''),\n",
    "                'retailer_id': df.get('retailer_id', '')\n",
    "            }\n",
    "            \n",
    "            mapped_df = pd.DataFrame(mapped_data)\n",
    "            \n",
    "            # Ajouter √† la liste\n",
    "            all_dataframes.append(mapped_df)\n",
    "            \n",
    "            files_processed += 1\n",
    "            total_products += len(mapped_df)\n",
    "            \n",
    "            print(f\"   ‚úì {len(mapped_df)} produits ajout√©s\")\n",
    "            print(f\"   Colonnes trouv√©es: {list(df.columns)}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Erreur: {str(e)}\\n\")\n",
    "            files_skipped += 1\n",
    "            continue\n",
    "    \n",
    "    # Fusionner tous les DataFrames\n",
    "    if not all_dataframes:\n",
    "        print(\"‚ùå Aucun fichier valide trouv√©!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üîó Fusion de {len(all_dataframes)} fichiers...\")\n",
    "    final_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Ajouter l'index d'ordonnancement\n",
    "    final_df.insert(0, 'ordering_index', range(len(final_df)))\n",
    "    \n",
    "    # R√©organiser les colonnes selon l'ordre final\n",
    "    final_df = final_df[final_columns]\n",
    "    \n",
    "    # Sauvegarder\n",
    "    print(f\"üíæ Sauvegarde dans: {output_file}\")\n",
    "    final_df.to_excel(output_file, index=False, engine='openpyxl')\n",
    "    \n",
    "    # R√©sum√© final\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚úÖ FUSION TERMIN√âE!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"üìä Fichiers trait√©s: {files_processed}\")\n",
    "    print(f\"‚ö†Ô∏è  Fichiers ignor√©s: {files_skipped}\")\n",
    "    print(f\"üõçÔ∏è  Total produits: {total_products}\")\n",
    "    print(f\"üìÅ Fichier cr√©√©: {output_file}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Aper√ßu des marques\n",
    "    print(\"üìà R√©partition par marque:\")\n",
    "    print(final_df['brand'].value_counts().to_string())\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    folder_path = r\"C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\cleaned_sheets\"\n",
    "    output_file = r\"C:\\Users\\aamir\\Desktop\\YC\\P\\spam-detection-nlp\\notebooks\\Catalog_products_columns_only.xlsx\"\n",
    "    \n",
    "    # Lancer la fusion\n",
    "    df_result = merge_product_catalogs(folder_path, output_file)\n",
    "    \n",
    "    # Afficher un aper√ßu\n",
    "    if df_result is not None:\n",
    "        print(\"\\nüëÄ Aper√ßu des 5 premi√®res lignes:\")\n",
    "        print(df_result.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
